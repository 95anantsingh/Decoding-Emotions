{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/as14229/NYU_HPC/Multilingual-Speech-Emotion-Recognition-System/jobs/'\n",
    "\n",
    "jobs_dir = os.path.join(base_dir,'sbatch')\n",
    "logs_base_dir = os.path.join(base_dir,'logs')\n",
    "os.makedirs(logs_base_dir,exist_ok=True)\n",
    "batch_number = max([int(d.split('_')[-1]) for d in os.listdir(logs_base_dir)]+[1])\n",
    "logs_dir = os.path.join(logs_base_dir,f'batch_{batch_number}')\n",
    "os.makedirs(logs_dir,exist_ok=True)\n",
    "if len(os.listdir(logs_dir))!=0:\n",
    "    logs_dir = os.path.join(logs_base_dir,f'batch_{batch_number+1}')\n",
    "\n",
    "scripts_dir = os.path.join(base_dir,'scripts')\n",
    "\n",
    "os.makedirs(jobs_dir,exist_ok=True)\n",
    "os.makedirs(logs_dir,exist_ok=True)\n",
    "os.makedirs(scripts_dir,exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Main Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbatch_header = f\"#!/bin/bash\\n\\\n",
    "\\n\\\n",
    "#SBATCH --nodes=1               \\n\\\n",
    "#SBATCH --ntasks-per-node=1     \\n\\\n",
    "#SBATCH --gres=gpu:1            \\n\"\n",
    "\n",
    "# partition list - sinfo -s\n",
    "\n",
    "job_name_directive =  \"#SBATCH --job-name=Job\"\n",
    "output_file_directive = \"#SBATCH --output=\"+logs_dir+'/job'\n",
    "\n",
    "command_header = \"\\nmodule purge\\n\\\n",
    "source ~/.bashrc\\n\\\n",
    "conda activate NLP_Nightly\\n\\\n",
    "cd /home/as14229/NYU_HPC/Multilingual-Speech-Emotion-Recognition-System/\\n\\n\"\n",
    "\n",
    "# Main Commmand\n",
    "command = \"python main.py -ll debug -em gpu_memory -nw 2 -cm DENSE \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_required_per_task = 128           # RAM required in GB\n",
    "job_params = dict(\n",
    "    time = \"4:00:00\",       # Time per job\n",
    "    # mem = '128GB', )               # RAM required in GB\n",
    "    partition = 'a100_1,a100_2,rtx8000')\n",
    "\n",
    "for param,val in job_params.items():\n",
    "    sbatch_header+=f'#SBATCH --{param}={val}\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n"
     ]
    }
   ],
   "source": [
    "# ['Run1','Run2','Run3','Run4','Run5']\n",
    "runs = ['Run2']\n",
    "# ['AESDD','CaFE','EmoDB','EMOVO','IEMOCAP','RAVDESS','ShEMO']\n",
    "datasets = ['RAVDESS']\n",
    "# ['GE2E','WAV2VEC2_BASE','WAV2VEC2_LARGE','WAV2VEC2_LARGE_XLSR','WAV2VEC2_LARGE_XLSR300M','HUBERT_BASE','HUBERT_LARGE','WAVLM_BASE','WAVLM_LARGE']\n",
    "models = ['WAV2VEC2_BASE']\n",
    "\n",
    "# sbatch_header+=f'#SBATCH --cpus-per-task={len(runs)}\\n'\n",
    "# sbatch_header+=f'#SBATCH --mem={min(250,memory_required_per_task*len(runs))}GB\\n'\n",
    "\n",
    "sbatch_header+=f'#SBATCH --cpus-per-task=4\\n'\n",
    "sbatch_header+=f'#SBATCH --mem={memory_required_per_task}GB\\n'\n",
    "\n",
    "jobs = []\n",
    "for run in runs:\n",
    "    for dataset in datasets:\n",
    "        for model in models:            \n",
    "            # c = f'{command} -d {dataset} -m {model} -r '\n",
    "            # for run in runs: c+=f' {run}'\n",
    "            # jobs.append(c)\n",
    "            jobs.append(f'{command} -d {dataset} -fm {model} -r {run}')\n",
    "print(sorted([int(m.split('.')[0][3:]) for m in os.listdir('sbatch')])[-1]+1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make SBATCH Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_start_number = sorted([int(m.split('.')[0][3:]) for m in os.listdir('sbatch')])[-1]+1\n",
    "\n",
    "jobs_per_gpu = 1                # Number of jobs per GPU\n",
    "# Make sbatch files\n",
    "for i,j in enumerate(range(0,len(jobs),jobs_per_gpu),job_start_number):\n",
    "    with open(os.path.join(jobs_dir,'job'+str(i)+'.sbatch'),'w') as file:\n",
    "        file.write(sbatch_header)\n",
    "        file.write(job_name_directive+str(i)+'\\n')\n",
    "        file.write(output_file_directive+str(i)+'.log\\n')\n",
    "        file.write(command_header)\n",
    "        for k in range(j,j+jobs_per_gpu):\n",
    "            jobs[k] += f' -jn Job{i}'\n",
    "            file.write(jobs[k])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Schedule File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schedule_file = os.path.join(scripts_dir,'schedule_jobs.sh')\n",
    "# with open(schedule_file,'w') as file:\n",
    "#     file.write('#!/bin/bash\\n\\n')\n",
    "#     for k in range(job_start_number,len(jobs)+job_start_number):\n",
    "#         file.write('sbatch '+jobs_dir+'/job'+str(k)+'.sbatch\\n')\n",
    "# os.chmod(schedule_file, 0o740)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = sorted([int(m.split('.')[0][3:]) for m in os.listdir('sbatch')])[-1]\n",
    "from_ = sorted([int(m.split('.')[0][3:]) for m in os.listdir('sbatch')])[0]\n",
    "\n",
    "schedule_file = os.path.join(scripts_dir,'schedule_jobs.sh')\n",
    "with open(schedule_file,'w') as file:\n",
    "    file.write('#!/bin/bash\\n\\n')\n",
    "    for k in range(from_,to+1):\n",
    "        file.write('sbatch '+jobs_dir+'/job'+str(k)+'.sbatch\\n')\n",
    "os.chmod(schedule_file, 0o740)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Cancel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancel_file = os.path.join(scripts_dir,'cancel_jobs.sh')\n",
    "# base_command = \"scancel $(sacct -n -X --format jobid --name\"\n",
    "# with open(cancel_file,'w') as file:\n",
    "#     file.write('#!/bin/bash\\n\\n')\n",
    "#     for k in range(job_start_number,len(jobs)+job_start_number):\n",
    "#         file.write(base_command+' Job'+str(k)+')\\n')\n",
    "# os.chmod(cancel_file, 0o740)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = sorted([int(m.split('.')[0][3:]) for m in os.listdir('sbatch')])[-1]\n",
    "from_ = sorted([int(m.split('.')[0][3:]) for m in os.listdir('sbatch')])[0]\n",
    "\n",
    "cancel_file = os.path.join(scripts_dir,'cancel_jobs.sh')\n",
    "base_command = \"scancel $(sacct -n -X --format jobid --name\"\n",
    "with open(cancel_file,'w') as file:\n",
    "    file.write('#!/bin/bash\\n\\n')\n",
    "    for k in range(from_,to+1):\n",
    "        file.write(base_command+' Job'+str(k)+')\\n')\n",
    "os.chmod(cancel_file, 0o740)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 30659173\n",
      "Submitted batch job 30659174\n",
      "Submitted batch job 30659175\n",
      "Submitted batch job 30659176\n",
      "Submitted batch job 30659177\n",
      "Submitted batch job 30659178\n",
      "Submitted batch job 30659179\n",
      "Submitted batch job 30659180\n",
      "Submitted batch job 30659181\n",
      "Submitted batch job 30659182\n",
      "Submitted batch job 30659183\n",
      "Submitted batch job 30659184\n",
      "Submitted batch job 30659185\n",
      "Submitted batch job 30659186\n",
      "Submitted batch job 30659187\n",
      "Submitted batch job 30659188\n",
      "Submitted batch job 30659189\n",
      "Submitted batch job 30659190\n",
      "Submitted batch job 30659191\n",
      "Submitted batch job 30659192\n",
      "Submitted batch job 30659193\n",
      "Submitted batch job 30659194\n",
      "Submitted batch job 30659195\n",
      "Submitted batch job 30659196\n",
      "Submitted batch job 30659197\n",
      "Submitted batch job 30659198\n",
      "Submitted batch job 30659199\n",
      "Submitted batch job 30659200\n",
      "Submitted batch job 30659201\n",
      "Submitted batch job 30659202\n",
      "Submitted batch job 30659203\n",
      "Submitted batch job 30659204\n",
      "Submitted batch job 30659205\n",
      "Submitted batch job 30659206\n",
      "Submitted batch job 30659207\n",
      "Submitted batch job 30659208\n",
      "Submitted batch job 30659209\n",
      "Submitted batch job 30659210\n",
      "Submitted batch job 30659211\n",
      "Submitted batch job 30659212\n",
      "Submitted batch job 30659213\n",
      "Submitted batch job 30659214\n",
      "Submitted batch job 30659215\n",
      "Submitted batch job 30659216\n",
      "Submitted batch job 30659217\n",
      "Submitted batch job 30659218\n",
      "Submitted batch job 30659219\n",
      "Submitted batch job 30659220\n",
      "Submitted batch job 30659221\n",
      "Submitted batch job 30659222\n",
      "Submitted batch job 30659223\n",
      "Submitted batch job 30659224\n",
      "Submitted batch job 30659225\n",
      "Submitted batch job 30659226\n",
      "Submitted batch job 30659227\n",
      "Submitted batch job 30659228\n",
      "Submitted batch job 30659229\n",
      "Submitted batch job 30659230\n",
      "Submitted batch job 30659231\n",
      "Submitted batch job 30659232\n",
      "Submitted batch job 30659233\n",
      "Submitted batch job 30659234\n",
      "Submitted batch job 30659235\n",
      "Submitted batch job 30659236\n",
      "Submitted batch job 30659237\n",
      "Submitted batch job 30659238\n",
      "Submitted batch job 30659239\n",
      "Submitted batch job 30659240\n",
      "Submitted batch job 30659241\n",
      "Submitted batch job 30659242\n",
      "Submitted batch job 30659243\n",
      "Submitted batch job 30659244\n",
      "Submitted batch job 30659245\n",
      "Submitted batch job 30659246\n",
      "Submitted batch job 30659247\n",
      "Submitted batch job 30659248\n",
      "Submitted batch job 30659249\n",
      "Submitted batch job 30659250\n",
      "Submitted batch job 30659251\n",
      "Submitted batch job 30659252\n",
      "Submitted batch job 30659253\n",
      "Submitted batch job 30659254\n",
      "Submitted batch job 30659255\n",
      "Submitted batch job 30659256\n",
      "Submitted batch job 30659257\n",
      "Submitted batch job 30659258\n",
      "Submitted batch job 30659259\n",
      "Submitted batch job 30659260\n",
      "Submitted batch job 30659261\n",
      "Submitted batch job 30659262\n",
      "Submitted batch job 30659263\n",
      "Submitted batch job 30659264\n",
      "Submitted batch job 30659265\n",
      "Submitted batch job 30659266\n",
      "Submitted batch job 30659267\n",
      "Submitted batch job 30659268\n",
      "Submitted batch job 30659269\n",
      "Submitted batch job 30659270\n",
      "Submitted batch job 30659271\n",
      "Submitted batch job 30659272\n",
      "Submitted batch job 30659273\n",
      "Submitted batch job 30659274\n",
      "Submitted batch job 30659275\n",
      "Submitted batch job 30659276\n",
      "Submitted batch job 30659277\n",
      "Submitted batch job 30659278\n",
      "Submitted batch job 30659279\n",
      "Submitted batch job 30659280\n",
      "Submitted batch job 30659281\n",
      "Submitted batch job 30659282\n",
      "Submitted batch job 30659283\n",
      "Submitted batch job 30659284\n",
      "Submitted batch job 30659285\n",
      "Submitted batch job 30659286\n",
      "Submitted batch job 30659287\n",
      "Submitted batch job 30659288\n",
      "Submitted batch job 30659289\n",
      "Submitted batch job 30659290\n",
      "Submitted batch job 30659291\n",
      "Submitted batch job 30659292\n",
      "Submitted batch job 30659293\n",
      "Submitted batch job 30659294\n",
      "Submitted batch job 30659295\n",
      "Submitted batch job 30659296\n",
      "Submitted batch job 30659297\n",
      "Submitted batch job 30659298\n",
      "Submitted batch job 30659299\n",
      "Submitted batch job 30659300\n",
      "Submitted batch job 30659301\n",
      "Submitted batch job 30659302\n",
      "Submitted batch job 30659303\n",
      "Submitted batch job 30659304\n",
      "Submitted batch job 30659305\n",
      "Submitted batch job 30659306\n",
      "Submitted batch job 30659307\n",
      "Submitted batch job 30659308\n",
      "Submitted batch job 30659309\n",
      "Submitted batch job 30659310\n",
      "Submitted batch job 30659311\n",
      "Submitted batch job 30659312\n",
      "Submitted batch job 30659313\n",
      "Submitted batch job 30659314\n",
      "Submitted batch job 30659315\n",
      "Submitted batch job 30659316\n",
      "Submitted batch job 30659317\n",
      "Submitted batch job 30659318\n",
      "Submitted batch job 30659319\n",
      "Submitted batch job 30659320\n",
      "Submitted batch job 30659321\n",
      "Submitted batch job 30659322\n",
      "Submitted batch job 30659323\n",
      "Submitted batch job 30659324\n",
      "Submitted batch job 30659325\n",
      "Submitted batch job 30659326\n",
      "Submitted batch job 30659327\n",
      "Submitted batch job 30659328\n",
      "Submitted batch job 30659329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = '/home/as14229/NYU_HPC/Multilingual-Speech-Emotion-Recognition-System/jobs/'\n",
    "scripts_dir = os.path.join(base_dir,'scripts')\n",
    "schedule_file = os.path.join(scripts_dir,'schedule_jobs.sh')\n",
    "# os.system(f'rm -rf {logs_dir}/*')\n",
    "os.system(f'bash {schedule_file}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancel Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = '/home/as14229/NYU_HPC/Multilingual-Speech-Emotion-Recognition-System/jobs/'\n",
    "scripts_dir = os.path.join(base_dir,'scripts')\n",
    "cancel_file = os.path.join(scripts_dir,'cancel_jobs.sh')\n",
    "os.system(f'bash {cancel_file}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Running Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "          30648359        cl   log1_0  as14229  R    4:16:59      1 cl001\n",
      "          30657827   rtx8000     bash  as14229  R      47:55      1 gr048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('squeue -u $USER -t running')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Pending Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "          30568428 rtx8000,v    Job35  as14229 PD       0:00      1 (Priority)\n",
      "          30568427 rtx8000,v    Job34  as14229 PD       0:00      1 (Priority)\n",
      "          30568426 rtx8000,v    Job33  as14229 PD       0:00      1 (Priority)\n",
      "          30568425 rtx8000,v    Job32  as14229 PD       0:00      1 (Priority)\n",
      "          30568424 rtx8000,v    Job31  as14229 PD       0:00      1 (Priority)\n",
      "          30568386 rtx8000,v    Job30  as14229 PD       0:00      1 (Priority)\n",
      "          30568385 rtx8000,v    Job29  as14229 PD       0:00      1 (Priority)\n",
      "          30568384 rtx8000,v    Job28  as14229 PD       0:00      1 (Priority)\n",
      "          30568383 rtx8000,v    Job27  as14229 PD       0:00      1 (Priority)\n",
      "          30568382 rtx8000,v    Job26  as14229 PD       0:00      1 (Priority)\n",
      "          30568381 rtx8000,v    Job25  as14229 PD       0:00      1 (Priority)\n",
      "          30568380 rtx8000,v    Job24  as14229 PD       0:00      1 (Priority)\n",
      "          30568379 rtx8000,v    Job23  as14229 PD       0:00      1 (Priority)\n",
      "          30568378 rtx8000,v    Job22  as14229 PD       0:00      1 (Priority)\n",
      "          30568377 rtx8000,v    Job21  as14229 PD       0:00      1 (Priority)\n",
      "          30568376 rtx8000,v    Job20  as14229 PD       0:00      1 (Priority)\n",
      "          30568375 rtx8000,v    Job19  as14229 PD       0:00      1 (Priority)\n",
      "          30568374 rtx8000,v    Job18  as14229 PD       0:00      1 (Priority)\n",
      "          30568373 rtx8000,v    Job17  as14229 PD       0:00      1 (Priority)\n",
      "          30568372 rtx8000,v    Job16  as14229 PD       0:00      1 (Priority)\n",
      "          30568371 rtx8000,v    Job15  as14229 PD       0:00      1 (Priority)\n",
      "          30568370 rtx8000,v    Job14  as14229 PD       0:00      1 (Priority)\n",
      "          30568369 rtx8000,v    Job13  as14229 PD       0:00      1 (Priority)\n",
      "          30568368 rtx8000,v    Job12  as14229 PD       0:00      1 (Priority)\n",
      "          30568367 rtx8000,v    Job11  as14229 PD       0:00      1 (Priority)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('squeue -u $USER -t pending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!scancel $(sacct -n -X --format jobid --name Job13)\n",
    "!scancel $(sacct -n -X --format jobid --name Job14)\n",
    "!scancel $(sacct -n -X --format jobid --name Job15)\n",
    "!scancel $(sacct -n -X --format jobid --name Job16)\n",
    "!scancel $(sacct -n -X --format jobid --name Job17)\n",
    "!scancel $(sacct -n -X --format jobid --name Job18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSERS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edf93a12d1b5ae7990448df3fb6c693d48c5ca93c427a6f205fa1a1fadc791bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
