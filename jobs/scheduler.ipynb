{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/as14229/NYU_HPC/Multilingual-Speech-Emotion-Recognition-System/jobs/'\n",
    "\n",
    "jobs_dir = os.path.join(base_dir,'sbatch')\n",
    "logs_base_dir = os.path.join(base_dir,'logs')\n",
    "\n",
    "batch_number = max([int(d.split('_')[-1]) for d in os.listdir(logs_base_dir)]+[1])\n",
    "logs_dir = os.path.join(logs_base_dir,f'batch_{batch_number}')\n",
    "if len(os.listdir(logs_dir))!=0:\n",
    "    logs_dir = os.path.join(logs_base_dir,f'batch_{batch_number+1}')\n",
    "\n",
    "scripts_dir = os.path.join(base_dir,'scripts')\n",
    "\n",
    "os.makedirs(jobs_dir,exist_ok=True)\n",
    "os.makedirs(logs_dir,exist_ok=True)\n",
    "os.makedirs(scripts_dir,exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Old Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(jobs_dir): \n",
    "#     os.system(f'rm -rf {jobs_dir}/*')\n",
    "#     os.system(f'rm -rf {logs_dir}/*')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Main Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbatch_header = f\"#!/bin/bash\\n\\\n",
    "\\n\\\n",
    "#SBATCH --nodes=1               \\n\\\n",
    "#SBATCH --ntasks-per-node=1     \\n\\\n",
    "#SBATCH --gres=gpu:1            \\n\"\n",
    "\n",
    "# partition list - sinfo -s\n",
    "\n",
    "job_name_directive =  \"#SBATCH --job-name=Job\"\n",
    "output_file_directive = \"#SBATCH --output=\"+logs_dir+'/job'\n",
    "\n",
    "command_header = \"\\nmodule purge\\n\\\n",
    "source ~/.bashrc\\n\\\n",
    "conda activate NLP_Nightly\\n\\\n",
    "cd /home/as14229/NYU_HPC/Multilingual-Speech-Emotion-Recognition-System/\\n\\n\"\n",
    "\n",
    "# Main Commmand\n",
    "command = \"python main.py -ll debug -em memory -nw 2 \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_required_per_task = 128           # RAM required in GB\n",
    "job_params = dict(\n",
    "    time = \"6:00:00\",)        # Time per job\n",
    "    # mem = '128GB', )               # RAM required in GB\n",
    "    # partition = 'a100_1,a100_2,rtx8000,v100')\n",
    "\n",
    "for param,val in job_params.items():\n",
    "    sbatch_header+=f'#SBATCH --{param}={val}\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = ['Run1','Run3','Run5']\n",
    "# ['AESDD','CaFE','EmoDB','EMOVO','IEMOCAP','RAVDESS','ShEMO']\n",
    "datasets = ['AESDD']\n",
    "# ['GE2E','WAV2VEC2_BASE','WAV2VEC2_LARGE','WAV2VEC2_LARGE_XLSR','WAV2VEC2_LARGE_XLSR300M','HUBERT_BASE','HUBERT_LARGE']\n",
    "models = ['HUBERT_LARGE']\n",
    "\n",
    "# sbatch_header+=f'#SBATCH --cpus-per-task={len(runs)}\\n'\n",
    "# sbatch_header+=f'#SBATCH --mem={min(250,memory_required_per_task*len(runs))}GB\\n'\n",
    "\n",
    "sbatch_header+=f'#SBATCH --cpus-per-task=4\\n'\n",
    "sbatch_header+=f'#SBATCH --mem={memory_required_per_task}GB\\n'\n",
    "\n",
    "jobs = []\n",
    "for run in runs:\n",
    "    for dataset in datasets:\n",
    "        for model in models:            \n",
    "            # c = f'{command} -d {dataset} -m {model} -r '\n",
    "            # for run in runs: c+=f' {run}'\n",
    "            # jobs.append(c)\n",
    "            jobs.append(f'{command} -d {dataset} -m {model} -r {run}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make SBATCH Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_start_number = 218\n",
    "\n",
    "jobs_per_gpu = 1                # Number of jobs per GPU\n",
    "# Make sbatch files\n",
    "for i,j in enumerate(range(0,len(jobs),jobs_per_gpu),job_start_number):\n",
    "    with open(os.path.join(jobs_dir,'job'+str(i)+'.sbatch'),'w') as file:\n",
    "        file.write(sbatch_header)\n",
    "        file.write(job_name_directive+str(i)+'\\n')\n",
    "        file.write(output_file_directive+str(i)+'.log\\n')\n",
    "        file.write(command_header)\n",
    "        for k in range(j,j+jobs_per_gpu):\n",
    "            jobs[k] += f' -jn Job{i}'\n",
    "            file.write(jobs[k])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Schedule File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_file = os.path.join(scripts_dir,'schedule_jobs.sh')\n",
    "with open(schedule_file,'w') as file:\n",
    "    file.write('#!/bin/bash\\n\\n')\n",
    "    for k in range(job_start_number,len(jobs)+job_start_number):\n",
    "        file.write('sbatch '+jobs_dir+'/job'+str(k)+'.sbatch\\n')\n",
    "os.chmod(schedule_file, 0o740)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Cancel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancel_file = os.path.join(scripts_dir,'cancel_jobs.sh')\n",
    "base_command = \"scancel $(sacct -n -X --format jobid --name\"\n",
    "with open(cancel_file,'w') as file:\n",
    "    file.write('#!/bin/bash\\n\\n')\n",
    "    for k in range(job_start_number,len(jobs)+job_start_number):\n",
    "        file.write(base_command+' Job'+str(k)+')\\n')\n",
    "os.chmod(cancel_file, 0o740)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 30595344\n",
      "Submitted batch job 30595345\n",
      "Submitted batch job 30595346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = '/home/as14229/NYU_HPC/Multilingual-Speech-Emotion-Recognition-System/jobs/'\n",
    "scripts_dir = os.path.join(base_dir,'scripts')\n",
    "schedule_file = os.path.join(scripts_dir,'schedule_jobs.sh')\n",
    "os.system(f'rm -rf {logs_dir}/*')\n",
    "os.system(f'bash {schedule_file}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancel Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = '/home/as14229/NYU_HPC/Multilingual-Speech-Emotion-Recognition-System/jobs/'\n",
    "scripts_dir = os.path.join(base_dir,'scripts')\n",
    "cancel_file = os.path.join(scripts_dir,'cancel_jobs.sh')\n",
    "os.system(f'bash {cancel_file}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Running Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "          30563939        cl     bash  as14229  R    9:20:18      1 cl001\n",
      "          30568366 gpu_misc_    Job10  as14229  R       8:50      1 gv016\n",
      "          30568364      v100     Job8  as14229  R      13:51      1 gv008\n",
      "          30568363      v100     Job7  as14229  R      15:51      1 gv002\n",
      "          30568357      v100     Job1  as14229  R      16:51      1 gv007\n",
      "          30568358      v100     Job2  as14229  R      16:51      1 gv001\n",
      "          30568360      v100     Job4  as14229  R      16:51      1 gv003\n",
      "          30568361      v100     Job5  as14229  R      16:51      1 gv004\n",
      "          30568362      v100     Job6  as14229  R      16:51      1 gv004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('squeue -u $USER -t running')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Pending Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "          30568428 rtx8000,v    Job35  as14229 PD       0:00      1 (Priority)\n",
      "          30568427 rtx8000,v    Job34  as14229 PD       0:00      1 (Priority)\n",
      "          30568426 rtx8000,v    Job33  as14229 PD       0:00      1 (Priority)\n",
      "          30568425 rtx8000,v    Job32  as14229 PD       0:00      1 (Priority)\n",
      "          30568424 rtx8000,v    Job31  as14229 PD       0:00      1 (Priority)\n",
      "          30568386 rtx8000,v    Job30  as14229 PD       0:00      1 (Priority)\n",
      "          30568385 rtx8000,v    Job29  as14229 PD       0:00      1 (Priority)\n",
      "          30568384 rtx8000,v    Job28  as14229 PD       0:00      1 (Priority)\n",
      "          30568383 rtx8000,v    Job27  as14229 PD       0:00      1 (Priority)\n",
      "          30568382 rtx8000,v    Job26  as14229 PD       0:00      1 (Priority)\n",
      "          30568381 rtx8000,v    Job25  as14229 PD       0:00      1 (Priority)\n",
      "          30568380 rtx8000,v    Job24  as14229 PD       0:00      1 (Priority)\n",
      "          30568379 rtx8000,v    Job23  as14229 PD       0:00      1 (Priority)\n",
      "          30568378 rtx8000,v    Job22  as14229 PD       0:00      1 (Priority)\n",
      "          30568377 rtx8000,v    Job21  as14229 PD       0:00      1 (Priority)\n",
      "          30568376 rtx8000,v    Job20  as14229 PD       0:00      1 (Priority)\n",
      "          30568375 rtx8000,v    Job19  as14229 PD       0:00      1 (Priority)\n",
      "          30568374 rtx8000,v    Job18  as14229 PD       0:00      1 (Priority)\n",
      "          30568373 rtx8000,v    Job17  as14229 PD       0:00      1 (Priority)\n",
      "          30568372 rtx8000,v    Job16  as14229 PD       0:00      1 (Priority)\n",
      "          30568371 rtx8000,v    Job15  as14229 PD       0:00      1 (Priority)\n",
      "          30568370 rtx8000,v    Job14  as14229 PD       0:00      1 (Priority)\n",
      "          30568369 rtx8000,v    Job13  as14229 PD       0:00      1 (Priority)\n",
      "          30568368 rtx8000,v    Job12  as14229 PD       0:00      1 (Priority)\n",
      "          30568367 rtx8000,v    Job11  as14229 PD       0:00      1 (Priority)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('squeue -u $USER -t pending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!scancel $(sacct -n -X --format jobid --name Job13)\n",
    "!scancel $(sacct -n -X --format jobid --name Job14)\n",
    "!scancel $(sacct -n -X --format jobid --name Job15)\n",
    "!scancel $(sacct -n -X --format jobid --name Job16)\n",
    "!scancel $(sacct -n -X --format jobid --name Job17)\n",
    "!scancel $(sacct -n -X --format jobid --name Job18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSERS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edf93a12d1b5ae7990448df3fb6c693d48c5ca93c427a6f205fa1a1fadc791bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
